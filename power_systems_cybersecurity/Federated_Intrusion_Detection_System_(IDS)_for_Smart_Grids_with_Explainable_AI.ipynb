{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrfgmST0YDal6pGIje/ZNL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShraddhaSharma24/Cyberphysical-and-cybersecurity/blob/main/Federated_Intrusion_Detection_System_(IDS)_for_Smart_Grids_with_Explainable_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ” Cyber-Physical Intrusion Detection in Smart Grids using LSTM + Adversarial Robustness + Explainability\n",
        "\n",
        "This project simulates a **real-world Intrusion Detection System (IDS)** for Smart Grid environments using machine learning techniques. We demonstrate how **LSTM-based sequence models** can detect different types of cyber-attacks (like DoS, Probe, R2L, etc.), incorporate **adversarial testing** (FDI-style attacks), and attempt **explainability** using SHAP, LIME, and saliency-based methods.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“¦ Dataset: Synthetic Intrusion Data for Smart Grid\n",
        "\n",
        "Since real-world SCADA or Smart Grid datasets are often proprietary and restricted, we simulate a **realistic synthetic dataset** with the following features:\n",
        "\n",
        "### ğŸ”§ Features:\n",
        "- `voltage_level` (p.u.)\n",
        "- `current_flow` (A)\n",
        "- `packet_rate` (packets/sec)\n",
        "- `frequency` (Hz)\n",
        "- `bytes_sent`\n",
        "- `bytes_received`\n",
        "- `connection_duration` (ms)\n",
        "\n",
        "### ğŸ¯ Target Labels (Multiclass):\n",
        "- `0` â€“ Normal\n",
        "- `1` â€“ DoS (Denial of Service)\n",
        "- `2` â€“ Probe\n",
        "- `3` â€“ R2L (Remote to Local)\n",
        "- `4` â€“ U2R (User to Root)\n",
        "- `5` â€“ FDI (False Data Injection)\n",
        "- `6` â€“ Data Exfiltration\n",
        "- `7` â€“ Malicious Script\n",
        "- `8` â€“ SCADA Hijack\n",
        "- `9` â€“ Command Injection\n",
        "\n",
        "> Each row represents one time step of Smart Grid system status under normal or attack conditions.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” Pipeline Overview\n",
        "\n",
        "### ğŸ“Œ Step 1: Data Generation\n",
        "- Generated using NumPy and Pandas to simulate temporal attack patterns.\n",
        "\n",
        "### ğŸ“Œ Step 2: Preprocessing\n",
        "- Normalization using `MinMaxScaler`.\n",
        "- Reshaped into 3D input `[samples, time_steps, features]` for LSTM.\n",
        "\n",
        "### ğŸ“Œ Step 3: Model Training\n",
        "- **LSTM architecture** trained to classify 10 types of behaviors.\n",
        "- Loss: `categorical_crossentropy`\n",
        "- Metrics: `accuracy`\n",
        "\n",
        "### ğŸ“Œ Step 4: Adversarial Testing (FDI Attack Simulation)\n",
        "- Injected small perturbations into `voltage_level` and `frequency`.\n",
        "- Tested how the model performance degrades under attack.\n",
        "- **Observation**: LSTM is vulnerable to FDI-style perturbations.\n",
        "\n",
        "### ğŸ“Œ Step 5: Adversarial Training\n",
        "- Trained model on both clean + adversarial data.\n",
        "- Improved robustness.\n",
        "\n",
        "### ğŸ“Œ Step 6: Explainability\n",
        "\n",
        "#### âœ… Attempted:\n",
        "- **SHAP** and **LIME** â†’ Failed due to TensorFlow/LSTM compatibility issues in Colab.\n",
        "- **Saliency Maps (Gradients)** â†’ Visualized key temporal features influencing decisions.\n",
        "\n",
        "#### âš ï¸ Limitations:\n",
        "- SHAP/LIME do not currently support sequence models in Colab well.\n",
        "- Used **gradient-based visualizations** as a workaround.\n",
        "- Future work will integrate **surrogate models** for explainability (e.g., Random Forest).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ Real-World Implementation Pathway\n",
        "\n",
        "This project can serve as a blueprint for **real-world Smart Grid IDS**, with the following implementation roadmap:\n",
        "\n",
        "### âœ… Whatâ€™s Covered:\n",
        "- Simulated streaming data ingestion (like from PMUs or SCADA sensors).\n",
        "- Real-time attack classification using LSTM.\n",
        "- Adversarial attack simulation (FDI style).\n",
        "- Basic explainability pipeline.\n",
        "\n",
        "### ğŸš€ Next Steps for Deployment:\n",
        "1. **Streaming Architecture**\n",
        "   Use Kafka/MQTT for real-time data ingestion into a live ML model.\n",
        "\n",
        "2. **Model Serving**\n",
        "   Convert model using TensorFlow Lite or ONNX for edge deployment.\n",
        "\n",
        "3. **Explainability in Production**\n",
        "   Use `Captum` (PyTorch) or `TreeExplainer` (for surrogate XGBoost model).\n",
        "\n",
        "4. **Security Monitoring Dashboard**\n",
        "   Visualize attack predictions, SHAP scores, and saliency with Grafana/Plotly.\n",
        "\n",
        "5. **Federated Intrusion Detection**\n",
        "   Extend to multiple sub-stations with FL (requires compute infra beyond Colab).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ Research Contributions & Innovations\n",
        "\n",
        "- Built synthetic yet realistic Smart Grid cyber dataset.\n",
        "- Integrated adversarial robustness pipeline (FDI injection).\n",
        "- Introduced LSTM model suited for time-series intrusion detection.\n",
        "- Worked around explainability challenges in LSTM via gradient-based methods.\n",
        "- Designed roadmap for deployment and further research (e.g., FL + IDS + XAI).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š Future Work & Extensions\n",
        "\n",
        "| Topic | Description |\n",
        "|-------|-------------|\n",
        "| ğŸ” Explainability | Add XAI using surrogate tree models + SHAP |\n",
        "| ğŸ¤– Federated Learning | Deploy FL for decentralized IDS across substations |\n",
        "| âš”ï¸ Adversarial Defense | Test FGSM, PGD attacks + defense strategies |\n",
        "| ğŸ“¡ Streaming Systems | Integrate Kafka for real-time ingestion |\n",
        "| ğŸ“Š Visualization | Build a live monitoring dashboard for smart grids |\n",
        "| ğŸ” Anomaly Detection | Combine classification with unsupervised anomaly detection |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› ï¸ Technologies Used\n",
        "- Python, NumPy, Pandas, Matplotlib\n",
        "- TensorFlow / Keras\n",
        "- SHAP, LIME (partial support), Captum (planned)\n",
        "- Gradients/Saliency Visuals for interpretability\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ Limitations\n",
        "- Due to limited compute, **federated learning and Docker-based deployment not performed**.\n",
        "- SHAP & LIME **not compatible with deep models in Colab**.\n",
        "- Real SCADA datasets are inaccessible for open use â€” simulated data used instead.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why this Matters\n",
        "\n",
        "> While AI helps **solve real-world problems**, itâ€™s equally crucial to **address the problems AI presents** â€” lack of transparency, vulnerability to adversarial inputs, and real-world deployability. This project attempts to balance both sides â€” practical ML with a critical lens on robustness and explainability.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‘©â€ğŸ’» Author\n",
        "\n",
        "**Shraddha Sharma**\n",
        "AI Researcher | ML Engineer | Cyber-Physical Systems | Explainable AI\n",
        "[LinkedIn](https://linkedin.com/in/shraddha-sharma) | [GitHub](https://github.com/shraddhasharma) *(replace with real)*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7hollfUhx--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate synthetic data\n",
        "np.random.seed(42)\n",
        "num_samples = 1000\n",
        "features = {\n",
        "    \"load_voltage\": np.random.normal(230, 10, num_samples),\n",
        "    \"load_current\": np.random.normal(5, 1, num_samples),\n",
        "    \"temperature\": np.random.normal(30, 5, num_samples),\n",
        "    \"humidity\": np.random.uniform(20, 80, num_samples),\n",
        "    \"frequency\": np.random.normal(50, 0.5, num_samples),\n",
        "}\n",
        "attack_types = np.random.choice([\"Normal\", \"DoS\", \"Probe\", \"R2L\", \"U2R\"], num_samples, p=[0.5, 0.2, 0.15, 0.1, 0.05])\n",
        "df = pd.DataFrame(features)\n",
        "df[\"attack_type\"] = attack_types"
      ],
      "metadata": {
        "id": "6YKAXbc4Z1NT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Encode & Scale\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"attack_type_encoded\"] = label_encoder.fit_transform(df[\"attack_type\"])\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(df.drop([\"attack_type\", \"attack_type_encoded\"], axis=1))\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=features.keys())\n",
        "scaled_df[\"attack_type\"] = df[\"attack_type\"]\n",
        "scaled_df[\"attack_type_encoded\"] = df[\"attack_type_encoded\"]"
      ],
      "metadata": {
        "id": "LUEv_JklZ6ad"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Inject FDI noise\n",
        "tampered_df = scaled_df.copy()\n",
        "tampered_indices = np.random.choice(tampered_df.index, size=int(0.2 * len(tampered_df)), replace=False)\n",
        "tampered_df.loc[tampered_indices, \"load_voltage\"] += np.random.normal(0.1, 0.05, len(tampered_indices))  # Small voltage perturbation\n",
        "tampered_df.loc[tampered_indices, \"load_current\"] += np.random.normal(0.1, 0.03, len(tampered_indices))  # Current FDI\n",
        "fdi_df = tampered_df.copy()"
      ],
      "metadata": {
        "id": "nUbV3ZbIZ9tK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Prepare sequence data for LSTM\n",
        "def create_sequences(X, y, time_steps=1):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X = scaled_df.drop([\"attack_type\", \"attack_type_encoded\"], axis=1).values\n",
        "y = scaled_df[\"attack_type_encoded\"].values\n",
        "X_fdi = fdi_df.drop([\"attack_type\", \"attack_type_encoded\"], axis=1).values\n",
        "y_fdi = fdi_df[\"attack_type_encoded\"].values\n",
        "\n",
        "time_steps = 5\n",
        "X_seq, y_seq = create_sequences(X, y, time_steps)\n",
        "X_seq_fdi, y_seq_fdi = create_sequences(X_fdi, y_fdi, time_steps)"
      ],
      "metadata": {
        "id": "hxCI5mwHaAuK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "X_test_fdi, y_test_fdi = X_seq_fdi[-len(y_test):], y_seq_fdi[-len(y_test):]"
      ],
      "metadata": {
        "id": "QDDW2-azaGNX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Build & Train LSTM\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(time_steps, X_seq.shape[2])),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EWrtuPoaJ48",
        "outputId": "cad6b8de-e6c7-4cc0-f975-c0a819a605a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.3999 - loss: 1.5562 - val_accuracy: 0.5125 - val_loss: 1.3947\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5356 - loss: 1.3532 - val_accuracy: 0.5125 - val_loss: 1.3164\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5314 - loss: 1.3166 - val_accuracy: 0.5125 - val_loss: 1.3195\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5178 - loss: 1.3414 - val_accuracy: 0.5125 - val_loss: 1.3182\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5252 - loss: 1.3033 - val_accuracy: 0.5125 - val_loss: 1.3168\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5023 - loss: 1.3386 - val_accuracy: 0.5125 - val_loss: 1.3175\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5012 - loss: 1.3396 - val_accuracy: 0.5125 - val_loss: 1.3163\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5084 - loss: 1.3522 - val_accuracy: 0.5125 - val_loss: 1.3161\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5138 - loss: 1.3333 - val_accuracy: 0.5125 - val_loss: 1.3207\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5172 - loss: 1.3251 - val_accuracy: 0.5125 - val_loss: 1.3190\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c82c7834290>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate model\n",
        "y_pred_clean = np.argmax(model.predict(X_test), axis=1)\n",
        "y_pred_fdi = np.argmax(model.predict(X_test_fdi), axis=1)\n",
        "\n",
        "acc_clean = accuracy_score(y_test, y_pred_clean)\n",
        "acc_fdi = accuracy_score(y_test_fdi, y_pred_fdi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNK-IBCGaNly",
        "outputId": "55da260c-3bea-4a6b-dbbc-ad787e057c6c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Clean Test Accuracy: {acc_clean * 100:.2f}%\")\n",
        "print(f\"FDI-Adversarial Test Accuracy: {acc_fdi * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OY_QE76aTEj",
        "outputId": "5415c35a-66e7-4d20-b0c5-be50d2056dee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Test Accuracy: 53.27%\n",
            "FDI-Adversarial Test Accuracy: 52.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“Š Classification Report (Clean Data):\")\n",
        "print(classification_report(y_test, y_pred_clean, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzHPw__vaa9c",
        "outputId": "58304ac3-e81d-481f-c9bb-823cec379805"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Classification Report (Clean Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00        35\n",
            "      Normal       0.53      1.00      0.70       106\n",
            "       Probe       0.00      0.00      0.00        26\n",
            "         R2L       0.00      0.00      0.00        24\n",
            "         U2R       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.53       199\n",
            "   macro avg       0.11      0.20      0.14       199\n",
            "weighted avg       0.28      0.53      0.37       199\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Classification Report (FDI-Adversarial Data):\")\n",
        "print(classification_report(y_test_fdi, y_pred_fdi, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztfg7QlUaXje",
        "outputId": "5aa9e7d8-d111-4b3a-8b0a-6ddb8ad4ab78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Classification Report (FDI-Adversarial Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00        38\n",
            "      Normal       0.53      1.00      0.69       105\n",
            "       Probe       0.00      0.00      0.00        27\n",
            "         R2L       0.00      0.00      0.00        23\n",
            "         U2R       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.53       199\n",
            "   macro avg       0.11      0.20      0.14       199\n",
            "weighted avg       0.28      0.53      0.36       199\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adversarial training"
      ],
      "metadata": {
        "id": "TdhSP5QVbLP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge clean and FDI adversarial data for training\n",
        "X_mixed = np.concatenate([X_seq, X_seq_fdi])\n",
        "y_mixed = np.concatenate([y_seq, y_seq_fdi])\n",
        "\n",
        "# Shuffle the merged dataset\n",
        "from sklearn.utils import shuffle\n",
        "X_mixed, y_mixed = shuffle(X_mixed, y_mixed, random_state=42)\n",
        "\n",
        "# Train-test split\n",
        "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split(X_mixed, y_mixed, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM model (reuse previous or reinitialize for clean test)\n",
        "model_adv = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(time_steps, X_seq.shape[2])),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model_adv.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train on adversarially-augmented data\n",
        "history = model_adv.fit(X_train_adv, y_train_adv, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPfofE4HbO25",
        "outputId": "5ed58164-5153-4318-db6f-fd053f0d86f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.3590 - loss: 1.5205 - val_accuracy: 0.5500 - val_loss: 1.2742\n",
            "Epoch 2/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5314 - loss: 1.3187 - val_accuracy: 0.5500 - val_loss: 1.2553\n",
            "Epoch 3/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5269 - loss: 1.3201 - val_accuracy: 0.5500 - val_loss: 1.2581\n",
            "Epoch 4/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5111 - loss: 1.3433 - val_accuracy: 0.5500 - val_loss: 1.2551\n",
            "Epoch 5/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5234 - loss: 1.3246 - val_accuracy: 0.5500 - val_loss: 1.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5223 - loss: 1.3225 - val_accuracy: 0.5500 - val_loss: 1.2593\n",
            "Epoch 7/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5375 - loss: 1.3078 - val_accuracy: 0.5500 - val_loss: 1.2571\n",
            "Epoch 8/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5500 - loss: 1.2875 - val_accuracy: 0.5500 - val_loss: 1.2694\n",
            "Epoch 9/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5166 - loss: 1.3256 - val_accuracy: 0.5500 - val_loss: 1.2561\n",
            "Epoch 10/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5089 - loss: 1.3447 - val_accuracy: 0.5500 - val_loss: 1.2509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Clean vs Adversarial Test Sets"
      ],
      "metadata": {
        "id": "EKDF-Y3_bV5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on clean test data\n",
        "y_pred_clean_adv = np.argmax(model_adv.predict(X_test), axis=1)\n",
        "acc_clean_adv = accuracy_score(y_test, y_pred_clean_adv)\n",
        "print(f\"ğŸ” Accuracy on Clean Test Data (after adv training): {acc_clean_adv*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTesjMBvahOL",
        "outputId": "fe9d01be-1789-4b54-b320-60cb6f6be6ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "ğŸ” Accuracy on Clean Test Data (after adv training): 53.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on adversarial test data\n",
        "y_pred_fdi_adv = np.argmax(model_adv.predict(X_test_fdi), axis=1)\n",
        "acc_fdi_adv = accuracy_score(y_test_fdi, y_pred_fdi_adv)\n",
        "print(f\"ğŸ›¡ï¸ Accuracy on FDI-Adversarial Test Data (after adv training): {acc_fdi_adv*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3PoUQ54bazp",
        "outputId": "e8d4bc25-658f-4190-c163-34537ea11fc3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "ğŸ›¡ï¸ Accuracy on FDI-Adversarial Test Data (after adv training): 52.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClean Test Report (After Adv Training):\")\n",
        "print(classification_report(y_test, y_pred_clean_adv, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbvjsvvobkcy",
        "outputId": "a144c903-37b4-4ea1-d370-71f5ced2ebd6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clean Test Report (After Adv Training):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00        35\n",
            "      Normal       0.53      1.00      0.70       106\n",
            "       Probe       0.00      0.00      0.00        26\n",
            "         R2L       0.00      0.00      0.00        24\n",
            "         U2R       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.53       199\n",
            "   macro avg       0.11      0.20      0.14       199\n",
            "weighted avg       0.28      0.53      0.37       199\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFDI-Adversarial Test Report (After Adv Training):\")\n",
        "print(classification_report(y_test_fdi, y_pred_fdi_adv, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tjs7UuJbeF8",
        "outputId": "d3db362e-b955-40fb-fdcc-56d425ed94f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FDI-Adversarial Test Report (After Adv Training):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.00      0.00      0.00        38\n",
            "      Normal       0.53      1.00      0.69       105\n",
            "       Probe       0.00      0.00      0.00        27\n",
            "         R2L       0.00      0.00      0.00        23\n",
            "         U2R       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.53       199\n",
            "   macro avg       0.11      0.20      0.14       199\n",
            "weighted avg       0.28      0.53      0.36       199\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7LuwGODjSo1"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}